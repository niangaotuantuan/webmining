install.packages(knitr)
install.packages("knitr")
This is an R Markdown document. Markdown is a simple formatting syntax for authoring web pages (click the **MD** toolbar button for help on Markdown).
install.packages('knitr')
library(tm)
library(kernlab)
library(Rstem)
library(Snowball) 
#ALSO NOTE********
#Snowball package may have problems installing due to Java Virtual Machine issues. During installation, R froze,
#I shut R down and was then able to install. May also need to install Rstem, which is located on http://www.omegahat.org/
#go to packages > select repositories>omegahat, and then you should be able to install from there
#In recent versions R, can use following options to install Rstem:
#options(CRAN = c(getOption("CRAN"), "http://www.omegahat.org/R"))
#install.packages("Rstem")
dir <- "E:\\"
setwd(dir)
#--------------tm package-------------------#
fea_mat <- read.table("dump_tense.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(fea_mat)
fea_mat <- read.table("dump_tense.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(fea_mat)
dim(fea_mat)
fea_mat <- fea_mat[,-1]
dim(fea_mat)
tfidf_mat <- fea_mat[,1:100]
added_mat <- fea_mat[,101:113]
tense_mat <- fea_mat[,114:115]
head(added_mat)
#Set Directory where Text is located
dir <- "E:\\Github\\webmining\\data"
setwd(dir)
#--------------tm package-------------------#
train_raw <- read.table("train.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(train_raw)
train_tweet <- train_raw[,2] #id, tweet, state, location
train_label <- train_raw[,5:28] #sentiment, when, weather
label_mat <- train_label
#train <- Corpus(x=train_tweet, readerControl=list(language="eng"))
#corpus <- Corpus(VectorSource(train_tweet))
train_tweet <- as.matrix(train_tweet)
corpus <- Corpus(VectorSource(train_tweet[1:500]))
label_s <- train_label[,1:5] #sentiment
label_w <- train_label[,6:9] #when
label_sw <- train_label[,1:9]
label_k <- train_label[,10:24] #weather
label_s[,3] <- as.numeric(label_s[,3])
save.image("E:\\Github\\webmining\\data\\.RData")
library(caret)
#library(devtools)
#install_github('caretEnsemble', 'zachmayer') #Install zach's caretEnsemble package
library(caretEnsemble)
library(randomForest)
#Data
#library(mlbench)
#data(BostonHousing2)
#X <- model.matrix(cmedv~crim+zn+indus+chas+nox+rm+age+dis+
#                    rad+tax+ptratio+b+lstat+lat+lon, BostonHousing2)[,-1]
#X <- data.frame(X)
#dtm
#X <- as.matrix(corpus.dtm)
#X <- data.frame(X)
X <- as.matrix(fea_mat[1:500,])
Y <- label_sw[1:500,1]
#Y <- BostonHousing2$cmedv
#Split train/test
train <- runif(nrow(X)) <= .66
#Setup CV Folds
#returnData=FALSE saves some space
folds=5
repeats=1
myControl <- trainControl(method='cv', number=folds, repeats=repeats, returnResamp='none', 
                          returnData=FALSE, savePredictions=TRUE, 
                          verboseIter=TRUE, allowParallel=TRUE,
                          index=createMultiFolds(Y[train], k=folds, times=repeats))
PP <- c('center', 'scale')
#Train some models
model1 <- train(X[train,], Y[train], method='gbm', trControl=myControl,
                tuneGrid=expand.grid(.n.trees=500, .interaction.depth=15, .shrinkage = 0.01))
model2 <- train(X[train,], Y[train], method='blackboost', trControl=myControl)
utils:::menuInstallPkgs()
utils:::menuInstallPkgs()
library(gbm)
library(mboost)
model1 <- train(X[train,], Y[train], method='gbm', trControl=myControl,
                tuneGrid=expand.grid(.n.trees=500, .interaction.depth=15, .shrinkage = 0.01))
model2 <- train(X[train,], Y[train], method='blackboost', trControl=myControl)
model2 <- train(X[train,], Y[train], method='blackboost', trControl=myControl)
?blackboost
model2 <- train(X[train,], Y[train], method='blackboost', maxdepth = 2, mstop = 50, trControl=myControl)
model2 <- train(X[train,], Y[train], method='blackboost', mstop = 50, trControl=myControl)
warnings()
utils:::menuInstallPkgs()
warnings()
model1 <- train(X[train,], Y[train], method='gbm', trControl=myControl,
                tuneGrid=expand.grid(.n.trees=500, .interaction.depth=15, .shrinkage = 0.01))
warnings()
model1
model2 <- train(X[train,], Y[train], method='blackboost', trControl=myControl)
warnings()
model4 <- train(X[train,], Y[train], method='mlpWeightDecay', trControl=myControl, trace=FALSE, preProcess=PP)
warnings()
utils:::menuInstallPkgs()
library(RSSNS)
library(RSNNS)
model4 <- train(X[train,], Y[train], method='mlpWeightDecay', trControl=myControl, trace=FALSE, preProcess=PP)
warnings()
model5 <- train(X[train,], Y[train], method='ppr', trControl=myControl, preProcess=PP)
warnings()
model6 <- train(X[train,], Y[train], method='earth', trControl=myControl, preProcess=PP)
utils:::menuInstallPkgs()
library(earth)
model6 <- train(X[train,], Y[train], method='earth', trControl=myControl, preProcess=PP)
str(fea_mat)
str(fea_mat[,50:100])
str(fea_mat[,101:115])
data <- train_raw[,-1]
data <- data[,-2]
data <- data[,-3]data <- train_raw[,-1]
data <- data[,-2]
data <- data[,-3]
data <- train_raw[,-1]
data <- data[,-2]
data <- data[,-3]
head(data)
head(train_raw)
data <- train_raw[,-1]
head(data)
datadata <- train_raw[,-1]
data <- data[,-2]
data <- data[,-2]
head(data)
clean.train <- data
## Modeling Begin
predictions <- NULL
NT <- 1000
## formula3 for 'gender' model using SVM
#formula3 <- as.factor(. ~ tweet)
## formula1 and formula2 both for rest features without gender model
#formula1.cf <- as.formula(as.factor(survived) ~ pclass  + alone + fare + age)
#formula2.cf <- as.formula(          survived  ~ pclass  + alone + fare + age)
## Train SVM(only for gender model) and Predict
library(e1071)
#formula3 <- as.factor(survived) ~ pclass + sex
formula3 <- s1+s2+s3+s4+s5+w1+w2+w3+w4+as.factor(k1)+as.factor(k2)+as.factor(k3)+as.factor(k4)+as.factor(k5)+as.factor(k6)+as.factor(k7)+as.factor(k8)+as.factor(k9)+as.factor(k10)+as.factor(k11)+as.factor(k12)+as.factor(k13)+as.factor(k14)+as.factor(k15) ~ tweet
tune <- tune.svm(formula3, data=clean.train, gamma=10^(-4:-1), cost=10^(1:4))
utils:::menuInstallPkgs()
library(e1071)
utils:::menuInstallPkgs()
clean.train <- data
## Modeling Begin
predictions <- NULL
NT <- 1000
## formula3 for 'gender' model using SVM
#formula3 <- as.factor(. ~ tweet)
## formula1 and formula2 both for rest features without gender model
#formula1.cf <- as.formula(as.factor(survived) ~ pclass  + alone + fare + age)
#formula2.cf <- as.formula(          survived  ~ pclass  + alone + fare + age)
## Train SVM(only for gender model) and Predict
library(e1071)
#formula3 <- as.factor(survived) ~ pclass + sex
formula3 <- s1+s2+s3+s4+s5+w1+w2+w3+w4+as.factor(k1)+as.factor(k2)+as.factor(k3)+as.factor(k4)+as.factor(k5)+as.factor(k6)+as.factor(k7)+as.factor(k8)+as.factor(k9)+as.factor(k10)+as.factor(k11)+as.factor(k12)+as.factor(k13)+as.factor(k14)+as.factor(k15) ~ tweet
tune <- tune.svm(formula3, data=clean.train, gamma=10^(-4:-1), cost=10^(1:4))
?tune.svm
clean.train <- fea_mat
## Modeling Begin
predictions <- NULL
NT <- 1000
## formula3 for 'gender' model using SVM
#formula3 <- as.factor(. ~ tweet)
## formula1 and formula2 both for rest features without gender model
#formula1.cf <- as.formula(as.factor(survived) ~ pclass  + alone + fare + age)
#formula2.cf <- as.formula(          survived  ~ pclass  + alone + fare + age)
## Train SVM(only for gender model) and Predict
library(e1071)
#formula3 <- as.factor(survived) ~ pclass + sex
formula3 <- s1+s2+s3+s4+s5+w1+w2+w3+w4+as.factor(k1)+as.factor(k2)+as.factor(k3)+as.factor(k4)+as.factor(k5)+as.factor(k6)+as.factor(k7)+as.factor(k8)+as.factor(k9)+as.factor(k10)+as.factor(k11)+as.factor(k12)+as.factor(k13)+as.factor(k14)+as.factor(k15) ~ X
Y <- s1+s2+s3+s4+s5+w1+w2+w3+w4+as.factor(k1)+as.factor(k2)+as.factor(k3)+as.factor(k4)+as.factor(k5)+as.factor(k6)+as.factor(k7)+as.factor(k8)+as.factor(k9)+as.factor(k10)+as.factor(k11)+as.factor(k12)+as.factor(k13)+as.factor(k14)+as.factor(k15)
tune <- tune.svm(y=Y, x=clean.train, gamma=10^(-4:-1), cost=10^(1:4))
tune_s <- tune.svm(y=label_s, x=clean.train, gamma=10^(-4:-1), cost=10^(1:4))
tune_s <- tune.svm(y=label_s[1:1000,], x=clean.train[1:1000,], gamma=10^(-4:-1), cost=10^(1:4))
warnings()
tune_s <- tune.svm(y=label_s[1:1000,], x=tfidf_mat[1:1000,], gamma=10^(-4:-1), cost=10^(1:4))
str(tfidf_mat)
str(label_s)
tune_s <- tune.svm(y=label_s[1:1000,], x=added_mat[1:1000,], gamma=10^(-4:-1), cost=10^(1:4))
warnings()
sum(added_mat[,1])
sum(added_mat[,2])
sum(added_mat[,3])
sum(added_mat[,4])
sum(added_mat[,5])
sum(added_mat[,6])
sum(added_mat[,7])
sum(added_mat[,8])
sum(added_mat[,9])
sum(added_mat[,10])
sum(added_mat[,11])
sum(added_mat[,12])
sum(added_mat[,13])
sum(added_mat[,14])
sum(tfidf_mat[,1]])
sum(tfidf_mat[,1])
sum(tfidf_mat[,2])
sum(tfidf_mat[,3])
sum(tfidf_mat[,4])
sum(tfidf_mat[,5])
sum(tfidf_mat[,6])
sum(tfidf_mat[,7])
sum(tfidf_mat[,8])
sum(tfidf_mat[,9])
sum(tfidf_mat[,10])
set.seed(42) #From random.org
train <- runif(nrow(X)) <= .33
X <- tfidf_mat
Y <- label_s
tune_s <- tune.svm(y=Y[train], x=X[train], gamma=10^(-4:-1), cost=10^(1:4))
str(train)
sum(train)
str(X)
dim(X)
X <- tfidf_mat
Y <- label_s
train <- runif(nrow(X)) <= .33
tune_s <- tune.svm(y=Y[train], x=X[train], gamma=10^(-4:-1), cost=10^(1:4))
str(train)
tune_s <- tune.svm(y=Y[train,], x=X[train,], gamma=10^(-4:-1), cost=10^(1:4))
q()
